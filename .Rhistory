summarise(chem=mean(chem),.groups = 'drop') %>% as.data.frame()
tmp_data = merge(tmp_wb, tmp_blood, by = c("Study_ID"), all = TRUE)
ggplot(data=tmp_data,aes(x=chem,y=adduct)) + geom_point() +
labs(y=adduct_name, x=chem_name)
cor(tmp_data$chem, tmp_data$adduct, method = c("pearson"), use = "pairwise.complete.obs")
tmp_blood = Blood_adduct[Blood_adduct$Sample_n==1,c("Study_ID",adduct_name,"Hemoglobin")]
tmp_blood$adduct = log(tmp_blood[[adduct_name]]/tmp_blood$Hemoglobin)
tmp_wb = WB_measurements[!is.na(WB_measurements[[chem_name]]),c("Study_ID",chem_name,"Time_WB_worn_D")]
tmp_wb$chem = log(tmp_wb[[chem_name]]/tmp_wb$Time_WB_worn_D)
tmp_wb <- tmp_wb %>% group_by(Study_ID) %>%
summarise(chem=mean(chem),.groups = 'drop') %>% as.data.frame()
tmp_data = merge(tmp_wb, tmp_blood, by = c("Study_ID"), all = TRUE)
ggplot(data=tmp_data,aes(x=chem,y=adduct)) + geom_point() +
labs(y=paste0("log(",adduct_name,"/Hgb)"), x=paste0("log(",chem_name,"/time)"))
cor(tmp_data$chem, tmp_data$adduct, method = c("pearson"),use = "pairwise.complete.obs")
pdf(file='~/Desktop/color_code.pdf',height=3,width=18)
par(mar=c(0,12,0,0))
plot(1:length(color_palette), type = "n", axes = FALSE, xlab = "", ylab = "", main = "")
# Plot squares with custom colors
for (i in 1:length(color_palette)) {
rect(i - 0.5, 0.5, i + 0.5, 10, col = color_palette[i], border = NA)
}
mtext("Subject ID", side = 2, line = 0, las = 1, cex = 3, padj=4)
dev.off()
pdf(file='~/Desktop/color_code.pdf',height=3,width=18)
par(mar=c(0,12,0,0))
plot(1:length(color_palette), type = "n", axes = FALSE, xlab = "", ylab = "", main = "")
# Plot squares with custom colors
for (i in 1:length(color_palette)) {
rect(i - 0.5, 0.5, i + 0.5, 10, col = color_palette[i], border = NA)
}
mtext("Subject ID", side = 2, line = 0, las = 1, cex = 3, padj=3)
dev.off()
pdf(file='~/Desktop/color_code.pdf',height=3,width=18)
par(mar=c(0,12,0,0))
plot(1:length(color_palette), type = "n", axes = FALSE, xlab = "", ylab = "", main = "")
# Plot squares with custom colors
for (i in 1:length(color_palette)) {
rect(i - 0.5, 0.5, i + 0.5, 10, col = color_palette[i], border = NA)
}
mtext("Subject ID", side = 2, line = 0, las = 1, cex = 3, padj=3.2)
dev.off()
rm(list=ls())
library(rstudioapi)
setwd(dirname(rstudioapi::getSourceEditorContext()$path)) #set the directory to the path of the current script
library("rstan")
library("bpr")
source("EPGLM_fcts.R")
######################################################
# DATA LOADING
######################################################
load(file="Data-and-Results/football_large_p.RData")
X <- as.matrix(data2[,-1])
y <- data2[,1]
p <- ncol(X)
# Hyper-parameters -------------------------------------------------------------
seed = 123          # seed for random number generation
tolerance = 1e-3          # tolerance for stopping iterative updates
nSample = 1e4       # number of MCMC samples
om2p     =  25*10/p  # marginal prior variances
Omega0   = diag(om2p,p,p)
beta0    = rep(0.,p)
# Split train-test -------------------------------------------------------------
set.seed(seed)
n        = length(y)
nTest    = 60
nTrain   = n-nTest
labTest = sample.int(n,nTest)
X_test = X[labTest,]
X      = X[-labTest,]
y_test = y[labTest]
y      = y[-labTest]
######################################################
# DEFINE POISSON MODEL IN STAN
######################################################
burn = 1e3
nChains_mcmc = 5
nSample_stan = as.integer(nSample/nChains_mcmc+burn) # so we have nSample samples after burnin
poissonGLM_diagPrior = 'data{
int<lower=0> K;
int<lower=0> N;
int<lower=0> Y[N];
matrix[N,K] X;
real<lower=0> devStd;
}
parameters {
vector[K] beta;
}
model {
for(j in 1:K)
beta[j] ~ normal(0,devStd);
for(i in 1:N)
Y[i] ~ poisson_log(X[i]*beta);
}'
######################################################
# GET HMC SAMPLES
######################################################
data_stan = list(N=nTrain,K=p,Y=as.vector(y),X=X,devStd=sqrt(om2p))
# If RUN=T run the code
RUN=F
if(RUN){
startTime = Sys.time()
HMC_Samples = stan(model_code = poissonGLM_diagPrior, data = data_stan, iter = nSample_stan,
warmup=burn, chains = nChains_mcmc, init="0", algorithm="NUTS", seed=seed, cores = nChains_mcmc)
betaHMC <- t(extract(HMC_Samples)$beta)
meanBetaHMC = apply(betaHMC,1,mean)
sdBetaHMC = apply(betaHMC,1,sd)
timeHMC = difftime(Sys.time(), startTime, units=("secs"))[[1]]
# prediction
predMeanHMC = rowMeans(exp(X_test%*%betaHMC))
timeHMCpredMean = difftime(Sys.time(), startTime, units=("secs"))[[1]] # timeMCMC_algo[i] + difftime(Sys.time(), startTime, units=("secs"))[[1]]
######################################################
# GET EP POSTERIOR MOMENTS
######################################################
startTime = Sys.time()
paramsEP = getParamsEP(X,y,family='poisson',Omega0=Omega0,beta0=beta0,approxHybrid=T,
fullVar=TRUE,damp=1.,nPrint=100,tolerance=tolerance,maxIter=1e5)
timeEP = difftime(Sys.time(), startTime, units=("secs"))[[1]]
# prediction
m_pred <- X_test%*%paramsEP$meanBeta
s2_pred <- rowSums(X_test*(X_test%*%paramsEP$Omega))
predMeanEP    = exp(m_pred+s2_pred/2)
timeEPpredMean = difftime(Sys.time(), startTime, units=("secs"))[[1]]
# store quantities
meanBetaEP = paramsEP$meanBeta
sdBetaEP = sqrt(paramsEP$diagOmega)
# save(meanBetaHMC,meanBetaEP,
#      sdBetaHMC,sdBetaEP,
#      predMeanHMC,predMeanEP,
#      timeHMC,timeEP,
#      timeHMCpredMean,timeEPpredMean,
#      file = "Data-and-Results/outputIllustrationPoisson_large_p_small_n.RData")
} else {
load("Data-and-Results/outputIllustrationPoisson_large_p_small_n.RData")
}
library(ggplot2)
library(reshape2)
library(scales)
colnames(meanBetaEP) = c("EP")
meanData = melt(meanBetaEP)[,-1]
meanData$group1 = c("Expectations")
meanData$y = c(meanBetaHMC)
sdBetaEP = as.matrix(sdBetaEP, ncols = 1)
colnames(sdBetaEP) = c("EP")
sdData = melt(sdBetaEP)[,-1]
sdData$group1 = c("Standard Deviations")
sdData$y = c(sdBetaHMC)
colnames(predMeanEP) = c("EP")
predData = melt(predMeanEP)[,-1]
predData$group1 = c("Predictive Means")
predData$y = c(predMeanHMC)
data_points = rbind(meanData,sdData,predData)
data_points$group1 = factor(data_points$group1, levels=c("Expectations", "Standard Deviations","Predictive Means" ))
P_Pois = ggplot(data_points, aes(y=value, x=y,color=c("red"))) +
geom_point(shape=21,fill="red",alpha=0.5)+facet_wrap(group1~., scales="free")+
geom_abline(slope = 1, intercept = 0, alpha = 0.7, lty = 2)+theme_bw()+
labs(x="Quantities computed from the exact posterior", y = "Quantities computed from the EP posterior")+
theme(strip.text.x = element_text(size = 15),axis.title.x = element_text(size=15),
axis.title.y = element_text(size=15), axis.text.y = element_text(size=15),
plot.margin = margin(0.1, 0.1, 0.05, 0.2, "cm"),legend.position = "none")+
scale_color_manual(values=c("red"))+
scale_shape_manual(values=c(1))+
scale_fill_manual(values=c("red"))
show(P_Pois)
rm(list=ls())
library(rstudioapi)
setwd(dirname(rstudioapi::getSourceEditorContext()$path)) #set the directory to the path of the current script
source("EPGLM_fcts.R")
library("TruncatedNormal")
library("truncnorm")
library("transport")
######################################################
# LOAD THE DATA
######################################################
load("Data-and-Results/Alzheimer_Interactions.RData")
seed = 1
set.seed(seed)
n = 300 # training set size
# split training and test sets
X_Test = X[-trainingSet,]
yTest = y[-trainingSet]
X = X[trainingSet,]
y = y[trainingSet]
# get number of covariates
p = dim(X)[2]
# prior variance
nu2 = 25
# fix number of samples
nSample = 1e4
# If RUN=T run the code
RUN=F
if(RUN){
# initialize vectors for predictive probabilities
predProbPFM    = double(length = length(yTest))
predProbEP     = double(length = length(yTest))
predProbMC     = double(length = length(yTest))
######################################################
# PFM
######################################################
tolerance = 1e-3 # tolerance to establish ELBO convergence
startTime = Sys.time()
paramsPFM = getParamsPFM(X=X,y=y,nu2=nu2,moments=TRUE,predictive=TRUE,tolerance=tolerance,maxIter=1e4)
timePFM = difftime(Sys.time(), startTime, units=("secs"))[[1]]
# posterior moments
meanPFM = paramsPFM$postMoments.meanBeta
sdPFM = sqrt(paramsPFM$postMoments.varBeta)
# predictive probabilities
# obtain a sample from q^*(z) to be used for the predictive probabilities of PFM
nSampleZ = 1e4
muTN = paramsPFM$mu
muTN[y==0] = -muTN[y==0]
sampleTruncNorm = matrix(rtruncnorm(n*nSampleZ, a = 0, b = Inf, mean = muTN, sd = sqrt(paramsPFM$sigma2)), nrow = n, ncol = nSampleZ, byrow = F )
sampleTruncNorm[y==0,] = -sampleTruncNorm[y==0,] # need to adjust the sign of the variables for which y_i is 0
for(j in 1:length(yTest)){
xNew = matrix(X_Test[j,],ncol = 1)
Xx = X%*%xNew
sd = as.double(sqrt(1+nu2*(sum(xNew^2)-nu2*t(Xx)%*%paramsPFM$predQuant.invIXXt%*%Xx)))
predProbPFM[j] = mean(pnorm((t(xNew)%*%paramsPFM$predQuant.VXt%*%sampleTruncNorm)/sd))
}
timePFMpredProb = difftime(Sys.time(), startTime, units=("secs"))[[1]]
######################################################
# EP
######################################################
Omega0   = diag(nu2,p,p)
beta0    = rep(0.,p)
startTime = Sys.time()
tolerance = 1e-3 # tolerance to establish convergence
paramsEP = getParamsEPprobit(X=X,y=y,nu2=nu2,tolerance=tolerance,predictive=T,fullVar = F,maxIter=1e4)
# paramsEP = getParamsEPprobit(X,y,family='probit',Omega0=Omega0,beta0=beta0,approxHybrid=T,fullVar=TRUE,damp=1.,nPrint=100,tolerance=tolerance,maxIter=1e5)
timeEP = difftime(Sys.time(), startTime, units=("secs"))[[1]]
# posterior moments
meanEP = paramsEP$meanBeta
sdEP = sqrt(paramsEP$diagOmega)
# predictive probabilities
for(j in 1:length(yTest)){
xNew = matrix(X_Test[j,],ncol = 1)
predProbEP[j] = as.double(predictEPprobit(paramsEP,xNew,nu2))
}
timeEPpredProb = difftime(Sys.time(), startTime, units=("secs"))[[1]]
######################################################
# EXACT SAMPLING
######################################################
startTime = Sys.time()
betaMC = rSUNpost(X=X,y=y,nu2=nu2,nSample=nSample)
# posterior moments
meanMC = apply(betaMC,1,mean)
sdMC = apply(betaMC,1,sd)
timeMC = difftime(Sys.time(), startTime, units=("secs"))[[1]]
# predictive probabilities
for(j in 1:length(yTest)){
xNew = matrix(X_Test[j,],ncol = 1)
predProbMC[j] = mean(pnorm(t(xNew)%*%betaMC))
}
timeMCpredProb = difftime(Sys.time(), startTime, units=("secs"))[[1]]
######################################################
# CHECK RUNNING TIMES AND NUMBER OF ITERATIONS
######################################################
timeMC # in second
timeMCpredProb # in seconds
timePFM # in seconds
timePFMpredProb # in seconds
timeEP # in seconds
timeEPpredProb # in seconds
paramsPFM$nIter
paramsEP$nIter
######################################################
# COMPUTE AND SAVE THE NEEDED SUMMARY STATISTICS
######################################################
# save(meanMC,meanPFM,meanEP,
#      predProbMC,predProbPFM,predProbEP,
#      sdMC,sdPFM,sdEP,
#      timeMC,timePFM,timeEP,
#      timeMCpredProb,timePFMpredProb,timeEPpredProb,
#      file = "Data-and-Results/outputIllustrationProbit.RData")
} else {
load("Data-and-Results/outputIllustrationProbit.RData")
}
library(ggplot2)
library(reshape)
library(RColorBrewer)
means = cbind(meanEP,meanPFM)
colnames(means) = c("EP","PFM-VB")
meanData = melt(means)[,-1]
meanData$group1 = c("Expectations")
meanData$y = c(meanMC,meanMC)
sds = cbind(sdEP,sdPFM)
colnames(sds) = c("EP","PFM-VB")
sdData = melt(sds)[,-1]
sdData$group1 = c("Standard Deviations")
sdData$y = c(sdMC,sdMC)
pred = cbind(predProbEP,predProbPFM)
colnames(pred) = c("EP","PFM-VB")
predData = melt(pred)[,-1]
predData$group1 = c("Predictive Probabilities")
predData$y = c(predProbMC,predProbMC)
######################################################################
# BOXPLOTS
######################################################################
### Comparison different methods via box-plot
EP_Diff_mean_Beta  = meanMC - meanEP
PFM_Diff_mean_Beta = meanMC - meanPFM
EP_Diff_logsd_Beta  = log(sdMC) - log(sdEP)
PFM_Diff_logsd_Beta = log(sdMC) - log(sdPFM)
EP_Diff_sd_Beta  = sdMC - sdEP
PFM_Diff_sd_Beta = sdMC - sdPFM
EP_Diff_predProb  = predProbMC - predProbEP
PFM_Diff_predProb = predProbMC - predProbPFM
Diff_Mean  = c(EP_Diff_mean_Beta, PFM_Diff_mean_Beta)
Diff_logsd = c(EP_Diff_logsd_Beta, PFM_Diff_logsd_Beta)
Diff_predProb = c(EP_Diff_predProb, PFM_Diff_predProb)
#Par        = as.factor(rep(rep(c(rep(1,n),rep(2,n)),3),2))
Method     = as.factor(
c(rep(rep(c("EP","PFM-VB"),each=length(EP_Diff_mean_Beta)),2),
rep(c("EP","PFM-VB"),each=length(EP_Diff_predProb)))
)
Functional = as.factor(c(rep(1:2,each=2*length(EP_Diff_mean_Beta)),
rep(3,2*length(EP_Diff_predProb)))
)
Diff       = c(Diff_Mean,Diff_logsd,Diff_predProb)
library("viridis")
library("latex2exp")
Data_boxplot = data.frame(Diff,Method,Functional)
scale_color_viridis(discrete=TRUE)
col_meth   = c("red","blue")
levels(Data_boxplot$Functional) =
c("1"=TeX("$\\Delta E(\\beta_{j} | y)$"),
"2"=TeX("$\\Delta \\log(\\sqrt{var(\\beta_{j} | y)})$"),
"3"=TeX("$\\Delta P(y_{n+1}=1 | y)$")
)
Data_boxplot$Method = factor(Data_boxplot$Method, c("EP","PFM-VB"))
Plot_Diff = ggplot(Data_boxplot, aes(y=Diff, x=Method,col=Method)) +
geom_boxplot()+
scale_colour_manual(values = alpha(col_meth,c(1,1)))+
theme_bw()+ geom_hline(yintercept=0, linetype="dashed", size=2)+
theme(axis.title=element_blank(),axis.text=element_text(size=15) ,
strip.text = element_text(size=15),legend.position = "none")+
facet_wrap(.~Functional, scales = "free", labeller=label_parsed)
Plot_Diff
rm(list=ls())
library(rstudioapi)
setwd(dirname(rstudioapi::getSourceEditorContext()$path)) #set the directory to the path of the current script
source("EPGLM_fcts.R")
library("TruncatedNormal")
library("truncnorm")
library("transport")
######################################################
# LOAD THE DATA
######################################################
load("Data-and-Results/Alzheimer_Interactions.RData")
seed = 1
set.seed(seed)
n = 300 # training set size
# split training and test sets
X_Test = X[-trainingSet,]
yTest = y[-trainingSet]
X = X[trainingSet,]
y = y[trainingSet]
# get number of covariates
p = dim(X)[2]
# prior variance
nu2 = 25
# fix number of samples
nSample = 1e4
# If RUN=T run the code
RUN=F
if(RUN){
# initialize vectors for predictive probabilities
predProbPFM    = double(length = length(yTest))
predProbEP     = double(length = length(yTest))
predProbMC     = double(length = length(yTest))
######################################################
# PFM
######################################################
tolerance = 1e-3 # tolerance to establish ELBO convergence
startTime = Sys.time()
paramsPFM = getParamsPFM(X=X,y=y,nu2=nu2,moments=TRUE,predictive=TRUE,tolerance=tolerance,maxIter=1e4)
timePFM = difftime(Sys.time(), startTime, units=("secs"))[[1]]
# posterior moments
meanPFM = paramsPFM$postMoments.meanBeta
sdPFM = sqrt(paramsPFM$postMoments.varBeta)
# predictive probabilities
# obtain a sample from q^*(z) to be used for the predictive probabilities of PFM
nSampleZ = 1e4
muTN = paramsPFM$mu
muTN[y==0] = -muTN[y==0]
sampleTruncNorm = matrix(rtruncnorm(n*nSampleZ, a = 0, b = Inf, mean = muTN, sd = sqrt(paramsPFM$sigma2)), nrow = n, ncol = nSampleZ, byrow = F )
sampleTruncNorm[y==0,] = -sampleTruncNorm[y==0,] # need to adjust the sign of the variables for which y_i is 0
for(j in 1:length(yTest)){
xNew = matrix(X_Test[j,],ncol = 1)
Xx = X%*%xNew
sd = as.double(sqrt(1+nu2*(sum(xNew^2)-nu2*t(Xx)%*%paramsPFM$predQuant.invIXXt%*%Xx)))
predProbPFM[j] = mean(pnorm((t(xNew)%*%paramsPFM$predQuant.VXt%*%sampleTruncNorm)/sd))
}
timePFMpredProb = difftime(Sys.time(), startTime, units=("secs"))[[1]]
######################################################
# EP
######################################################
Omega0   = diag(nu2,p,p)
beta0    = rep(0.,p)
startTime = Sys.time()
tolerance = 1e-3 # tolerance to establish convergence
paramsEP = getParamsEPprobit(X=X,y=y,nu2=nu2,tolerance=tolerance,predictive=T,fullVar = F,maxIter=1e4)
# paramsEP = getParamsEPprobit(X,y,family='probit',Omega0=Omega0,beta0=beta0,approxHybrid=T,fullVar=TRUE,damp=1.,nPrint=100,tolerance=tolerance,maxIter=1e5)
timeEP = difftime(Sys.time(), startTime, units=("secs"))[[1]]
# posterior moments
meanEP = paramsEP$meanBeta
sdEP = sqrt(paramsEP$diagOmega)
# predictive probabilities
for(j in 1:length(yTest)){
xNew = matrix(X_Test[j,],ncol = 1)
predProbEP[j] = as.double(predictEPprobit(paramsEP,xNew,nu2))
}
timeEPpredProb = difftime(Sys.time(), startTime, units=("secs"))[[1]]
######################################################
# EXACT SAMPLING
######################################################
startTime = Sys.time()
betaMC = rSUNpost(X=X,y=y,nu2=nu2,nSample=nSample)
# posterior moments
meanMC = apply(betaMC,1,mean)
sdMC = apply(betaMC,1,sd)
timeMC = difftime(Sys.time(), startTime, units=("secs"))[[1]]
# predictive probabilities
for(j in 1:length(yTest)){
xNew = matrix(X_Test[j,],ncol = 1)
predProbMC[j] = mean(pnorm(t(xNew)%*%betaMC))
}
timeMCpredProb = difftime(Sys.time(), startTime, units=("secs"))[[1]]
######################################################
# CHECK RUNNING TIMES AND NUMBER OF ITERATIONS
######################################################
timeMC # in second
timeMCpredProb # in seconds
timePFM # in seconds
timePFMpredProb # in seconds
timeEP # in seconds
timeEPpredProb # in seconds
paramsPFM$nIter
paramsEP$nIter
######################################################
# COMPUTE AND SAVE THE NEEDED SUMMARY STATISTICS
######################################################
# save(meanMC,meanPFM,meanEP,
#      predProbMC,predProbPFM,predProbEP,
#      sdMC,sdPFM,sdEP,
#      timeMC,timePFM,timeEP,
#      timeMCpredProb,timePFMpredProb,timeEPpredProb,
#      file = "Data-and-Results/outputIllustrationProbit.RData")
} else {
load("Data-and-Results/outputIllustrationProbit.RData")
}
library(ggplot2)
library(reshape)
library(RColorBrewer)
means = cbind(meanEP,meanPFM)
colnames(means) = c("EP","PFM-VB")
meanData = melt(means)[,-1]
meanData$group1 = c("Expectations")
meanData$y = c(meanMC,meanMC)
sds = cbind(sdEP,sdPFM)
colnames(sds) = c("EP","PFM-VB")
sdData = melt(sds)[,-1]
sdData$group1 = c("Standard Deviations")
sdData$y = c(sdMC,sdMC)
pred = cbind(predProbEP,predProbPFM)
colnames(pred) = c("EP","PFM-VB")
predData = melt(pred)[,-1]
predData$group1 = c("Predictive Probabilities")
predData$y = c(predProbMC,predProbMC)
######################################################################
# BOXPLOTS
######################################################################
### Comparison different methods via box-plot
EP_Diff_mean_Beta  = meanMC - meanEP
PFM_Diff_mean_Beta = meanMC - meanPFM
EP_Diff_logsd_Beta  = log(sdMC) - log(sdEP)
PFM_Diff_logsd_Beta = log(sdMC) - log(sdPFM)
EP_Diff_sd_Beta  = sdMC - sdEP
PFM_Diff_sd_Beta = sdMC - sdPFM
EP_Diff_predProb  = predProbMC - predProbEP
PFM_Diff_predProb = predProbMC - predProbPFM
Diff_Mean  = c(EP_Diff_mean_Beta, PFM_Diff_mean_Beta)
Diff_logsd = c(EP_Diff_logsd_Beta, PFM_Diff_logsd_Beta)
Diff_predProb = c(EP_Diff_predProb, PFM_Diff_predProb)
#Par        = as.factor(rep(rep(c(rep(1,n),rep(2,n)),3),2))
Method     = as.factor(
c(rep(rep(c("EP","PFM-VB"),each=length(EP_Diff_mean_Beta)),2),
rep(c("EP","PFM-VB"),each=length(EP_Diff_predProb)))
)
Functional = as.factor(c(rep(1:2,each=2*length(EP_Diff_mean_Beta)),
rep(3,2*length(EP_Diff_predProb)))
)
Diff       = c(Diff_Mean,Diff_logsd,Diff_predProb)
library("viridis")
library("latex2exp")
Data_boxplot = data.frame(Diff,Method,Functional)
scale_color_viridis(discrete=TRUE)
col_meth   = c("red","blue")
levels(Data_boxplot$Functional) =
c("1"=TeX("$\\Delta E(\\beta_{j} | y)$"),
"2"=TeX("$\\Delta \\log(\\sqrt{var(\\beta_{j} | y)})$"),
"3"=TeX("$\\Delta P(y_{n+1}=1 | y)$")
)
Data_boxplot$Method = factor(Data_boxplot$Method, c("EP","PFM-VB"))
Plot_Diff = ggplot(Data_boxplot, aes(y=Diff, x=Method,col=Method)) +
geom_boxplot()+
scale_colour_manual(values = alpha(col_meth,c(1,1)))+
theme_bw()+ geom_hline(yintercept=0, linetype="dashed", linewidth=2)+
theme(axis.title=element_blank(),axis.text=element_text(size=15) ,
strip.text = element_text(size=15),legend.position = "none")+
facet_wrap(.~Functional, scales = "free", labeller=label_parsed)
Plot_Diff
